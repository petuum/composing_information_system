{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murphy/anaconda3/envs/composing_info_sys/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"allennlp\": {\n",
      "    \"allow_parallel_entries\": true,\n",
      "    \"cuda_devices\": [\n",
      "      0,\n",
      "      1\n",
      "    ],\n",
      "    \"overwrite_entries\": false,\n",
      "    \"processors\": \"tokenize, srl\",\n",
      "    \"srl_url\": \"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\",\n",
      "    \"tag_formalism\": \"srl\"\n",
      "  },\n",
      "  \"allennlp_query\": {\n",
      "    \"allow_parallel_entries\": true,\n",
      "    \"overwrite_entries\": false,\n",
      "    \"processors\": [\n",
      "      \"tokenize\",\n",
      "      \"pos\",\n",
      "      \"srl\"\n",
      "    ],\n",
      "    \"srl_url\": \"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\",\n",
      "    \"tag_formalism\": \"srl\"\n",
      "  },\n",
      "  \"boxer\": {\n",
      "    \"pack_name\": \"query\"\n",
      "  },\n",
      "  \"indexer\": {\n",
      "    \"field\": \"content\",\n",
      "    \"index_config\": {\n",
      "      \"algorithm\": \"bm25\",\n",
      "      \"hosts\": \"localhost:9200\",\n",
      "      \"index_name\": \"elastic_index\"\n",
      "    },\n",
      "    \"indexed_text_only\": false,\n",
      "    \"query_pack_name\": \"query\",\n",
      "    \"response_pack_name_prefix\": \"passage\"\n",
      "  },\n",
      "  \"query_creator\": {\n",
      "    \"field\": \"content\",\n",
      "    \"query_pack_name\": \"query\",\n",
      "    \"size\": 10\n",
      "  },\n",
      "  \"reader\": {\n",
      "    \"pack_name\": \"query\"\n",
      "  },\n",
      "  \"response\": {\n",
      "    \"query_pack_name\": \"query\"\n",
      "  },\n",
      "  \"spacy1\": {\n",
      "    \"lang\": \"en_ner_bionlp13cg_md\",\n",
      "    \"processors\": [\n",
      "      \"sentence\",\n",
      "      \"umls_link\"\n",
      "    ]\n",
      "  },\n",
      "  \"spacy2\": {\n",
      "    \"lang\": \"en_ner_jnlpba_md\",\n",
      "    \"processors\": \"umls_link\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create a Forte pipeline.\n",
    "\"\"\"\n",
    "import forte\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "nlp = forte.pipeline.Pipeline()\n",
    "# An example configuration for the pipeline is provided in this repo\n",
    "config_file = os.path.join('examples/pipeline/inference/config.yml')\n",
    "config = yaml.safe_load(open(config_file, \"r\"))\n",
    "config = forte.common.configuration.Config(config, default_hparams=None)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Re-declared a new class named [ConstituentNode], which is probably used in import.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what does covid cause\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Attach a reader to the pipeline.\n",
    "\"\"\"\n",
    "from forte.data.readers import MultiPackTerminalReader\n",
    "nlp.set_reader(MultiPackTerminalReader(), config=config.reader).initialize()\n",
    "# process_dataset() returns a Python iterator of data (MultiPack in this case)\n",
    "# returned by `MultiPackTerminalReader`\n",
    "print(next(nlp.process_dataset()).get_pack_at(0).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murphy/anaconda3/envs/composing_info_sys/lib/python3.6/site-packages/forte/data/selector.py:138: UserWarning: Passing parameters through __init__ is deprecated, and does not work well with pipeline serialization.\n",
      "  \"Passing parameters through __init__ is deprecated,\"\n",
      "WARNING:root:Re-declared a new class named [ConstituentNode], which is probably used in import.\n",
      "[nltk_data] Downloading package punkt to /home/murphy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/murphy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/murphy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "WARNING:allennlp.data.fields.sequence_label_field:Your label namespace was 'pos'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens created by NLTK:\n",
      "    text: what, pos: WP, lemma: what\n",
      "    text: does, pos: VBZ, lemma: do\n",
      "    text: covid, pos: NN, lemma: covid\n",
      "    text: cause, pos: NN, lemma: cause\n",
      "Semantic role labels created by AllenNLP:\n",
      "    verb: cause, noun: what, noun_type: ARG1\n",
      "    verb: cause, noun: covid, noun_type: ARG0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add NLP processors to extract necessary language features such as\n",
    "POS (Parts of Speech), Lemma and SRL (Semantic Role Labeling).\n",
    "\"\"\"\n",
    "from fortex.nltk.nltk_processors import NLTKLemmatizer, \\\n",
    "    NLTKSentenceSegmenter, NLTKWordTokenizer, NLTKPOSTagger\n",
    "from fortex.allennlp.allennlp_processors import AllenNLPProcessor\n",
    "from forte.data.selector import NameMatchSelector\n",
    "\n",
    "selector = NameMatchSelector(select_name=config.reader.pack_name)\n",
    "nlp.add(NLTKSentenceSegmenter(), selector=selector)\n",
    "nlp.add(NLTKWordTokenizer(), selector=selector)\n",
    "nlp.add(NLTKPOSTagger(), selector=selector)\n",
    "nlp.add(NLTKLemmatizer(), selector=selector)\n",
    "nlp.add(AllenNLPProcessor(), config=config.allennlp_query, selector=selector)\n",
    "\n",
    "# See what's in the result data pack\n",
    "nlp.initialize()\n",
    "from ft.onto.base_ontology import Token, Sentence, PredicateLink\n",
    "data_pack = next(nlp.process_dataset()).get_pack_at(0)\n",
    "for sent in data_pack.get(Sentence):\n",
    "    print(\"Tokens created by NLTK:\")\n",
    "    for token in data_pack.get(Token, sent, components=[\"fortex.nltk.nltk_processors.NLTKWordTokenizer\"]):\n",
    "        print(f\"    text: {data_pack.text[token.begin:token.end]}, pos: {token.pos}, lemma: {token.lemma}\")\n",
    "    print(\"Semantic role labels created by AllenNLP:\")\n",
    "    for pred in data_pack.get(PredicateLink, sent, components=[\"fortex.allennlp.allennlp_processors.AllenNLPProcessor\"]):\n",
    "        verb = pred.get_parent()\n",
    "        noun = pred.get_child()\n",
    "        print(f\"    verb: {data_pack.text[verb.begin:verb.end]}, noun: {data_pack.text[noun.begin:noun.end]}, noun_type: {pred.arg_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Re-declared a new class named [ConstituentNode], which is probably used in import.\n",
      "[nltk_data] Downloading package punkt to /home/murphy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/murphy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/murphy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "INFO:elasticsearch:GET http://localhost:9200/ [status:200 request:0.004s]\n",
      "INFO:elasticsearch:POST http://localhost:9200/elastic_index/_search [status:200 request:0.061s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(document_class=[], sentiment={}, classifications=<forte.data.ontology.core.FDict object at 0x7f6d1d822a58>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use above extracted language features to create an Elastic Search (ES) query\n",
    "and retrieve relevant documents from an ES database.\n",
    "\"\"\"\n",
    "from typing import Any, Dict, Tuple\n",
    "from forte.data.data_pack import DataPack\n",
    "from forte.data.multi_pack import MultiPack\n",
    "from forte.processors.base import QueryProcessor\n",
    "from fortex.elastic.elastic_search_processor import ElasticSearchProcessor\n",
    "# from composable_source.processors.elasticsearch_query_creator import ElasticSearchQueryCreator\n",
    "from composable_source.utils.utils import query_preprocess\n",
    "\n",
    "\n",
    "class ElasticSearchQueryCreator(QueryProcessor):\n",
    "    \"\"\"\n",
    "    Complete implementation is available at composable_source/processors/elasticsearch_query_creator.py\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def default_configs(cls) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"size\": 1000,\n",
    "            \"field\": \"content\",\n",
    "            \"query_pack_name\": \"query\"\n",
    "        }\n",
    "\n",
    "    def _process_query(self, input_pack: MultiPack) -> Tuple[DataPack, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        process query datapack and return query\n",
    "        :param input_pack:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        query_pack = input_pack.get_pack(self.configs.query_pack_name)\n",
    "        query_pack.pack_name = self.configs.query_pack_name\n",
    "        query = self._build_query_nlp(query_pack)\n",
    "        return query_pack, query\n",
    "    \n",
    "    def _build_query_nlp(self, input_pack: DataPack) -> Dict[str, Any]:\n",
    "        query, arg0, arg1, verb, _, is_answer_arg0 = query_preprocess(input_pack)\n",
    "        if not arg0 or not arg1:\n",
    "            processed_query = query\n",
    "        if is_answer_arg0 is None:\n",
    "            processed_query = f'{arg0} {verb} {arg1}'.lower()\n",
    "        elif is_answer_arg0:\n",
    "            processed_query = f'{arg1} {verb}'.lower()\n",
    "        else:\n",
    "            processed_query = f'{arg0} {verb}'.lower()\n",
    "        return {\n",
    "            \"query\": {\n",
    "                \"match_phrase\": {\n",
    "                    self.configs.field: {\n",
    "                        \"query\": processed_query,\n",
    "                        \"slop\": 10  # how far we allow the terms to be\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"size\": self.configs.size\n",
    "        }\n",
    "\n",
    "nlp.add(ElasticSearchQueryCreator(), config=config.query_creator)\n",
    "nlp.add(ElasticSearchProcessor(), config=config.indexer)\n",
    "\n",
    "# See what's in the result data pack\n",
    "nlp.initialize()\n",
    "data_pack = next(nlp.process_dataset()).get_pack_at(1)\n",
    "from ft.onto.base_ontology import Document\n",
    "data_pack.get_single(Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murphy/anaconda3/envs/composing_info_sys/lib/python3.6/site-packages/forte/data/selector.py:206: UserWarning: Passing parameters through __init__ is deprecated, and does not work well with pipeline serialization.\n",
      "  \"Passing parameters through __init__ is deprecated,\"\n",
      "WARNING:root:Re-declared a new class named [ConstituentNode], which is probably used in import.\n",
      "[nltk_data] Downloading package punkt to /home/murphy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/murphy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/murphy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/murphy/anaconda3/envs/composing_info_sys/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.20.3 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/murphy/anaconda3/envs/composing_info_sys/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.20.3 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/murphy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/murphy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "INFO:elasticsearch:GET http://localhost:9200/ [status:200 request:0.004s]\n",
      "INFO:elasticsearch:POST http://localhost:9200/elastic_index/_search [status:200 request:0.052s]\n",
      "/home/murphy/anaconda3/envs/composing_info_sys/lib/python3.6/site-packages/scispacy/candidate_generation.py:284: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  extended_neighbors[empty_vectors_boolean_flags] = numpy.array(neighbors)[:-1]\n",
      "/home/murphy/anaconda3/envs/composing_info_sys/lib/python3.6/site-packages/scispacy/candidate_generation.py:285: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  extended_distances[empty_vectors_boolean_flags] = numpy.array(distances)[:-1]\n",
      "WARNING:allennlp.models.model:Encountered the arc_loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
      "WARNING:allennlp.models.model:Encountered the tag_loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n",
      "WARNING:allennlp.models.model:Encountered the loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Assessing the Country-Level Excess All-Cause Mortality and the Impacts of Air Pollution and Human Activity during the COVID-19 Epidemic\n",
      "\n",
      "Citation:\n",
      "Entities created by SciSpacy:\n",
      "    entity: Homo sapiens, cui: C0086418\n",
      "    entity: Humanin, human, cui: C4318409\n",
      "    entity: Bone Tissue, Human, cui: C4520924\n",
      "    entity: Approved for Human Use Product, cui: C4055445\n",
      "    entity: AR protein, human, cui: C1447749\n",
      "    entity: COVID-19, cui: C5203670\n",
      "Semantic role labels created by AllenNLP:\n",
      "    verb: Assessing, noun: the Country-Level Excess All-Cause Mortality and the Impacts of Air Pollution and Human Activity, noun_type: ARG1\n",
      "    verb: Assessing, noun: during the COVID-19 Epidemic\n",
      "\n",
      "Citation, noun_type: ARGM-TMP\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add NLP processors to extract necessary language features such as Entity links and SRL.\n",
    "\"\"\"\n",
    "from fortex.spacy.spacy_processors import SpacyProcessor\n",
    "from forte.data.selector import RegexNameMatchSelector\n",
    "pattern = rf\"{config.indexer.response_pack_name_prefix}_\\d\"\n",
    "selector = RegexNameMatchSelector(select_name=pattern)\n",
    "nlp.add(component=SpacyProcessor(), config=config.spacy1, selector=selector)\n",
    "nlp.add(component=SpacyProcessor(), config=config.spacy2, selector=selector)\n",
    "nlp.add(AllenNLPProcessor(), config=config.allennlp, selector=selector)\n",
    "nlp.add(NLTKPOSTagger(), selector=selector)\n",
    "nlp.add(NLTKLemmatizer(), selector=selector)\n",
    "\n",
    "# See what's in the result data pack\n",
    "from ftx.onto.clinical import MedicalEntityMention\n",
    "from ft.onto.base_ontology import Sentence\n",
    "nlp.initialize()\n",
    "data_pack = next(nlp.process_dataset()).get_pack_at(1)\n",
    "sent = data_pack.get_single(Sentence)\n",
    "\n",
    "print(f\"Sentence: {sent.text}\")\n",
    "print(\"Entities created by SciSpacy:\")\n",
    "for entity in data_pack.get(MedicalEntityMention, sent):\n",
    "    for umls in entity.umls_entities:\n",
    "        print(f\"    entity: {umls.name}, cui: {umls.cui}\")\n",
    "print(\"Semantic role labels created by AllenNLP:\")\n",
    "for pred in data_pack.get(PredicateLink, sent):\n",
    "    verb = pred.get_parent()\n",
    "    noun = pred.get_child()\n",
    "    print(f\"    verb: {data_pack.text[verb.begin:verb.end]}, noun: {data_pack.text[noun.begin:noun.end]}, noun_type: {pred.arg_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Re-declared a new class named [ConstituentNode], which is probably used in import.\n",
      "[nltk_data] Downloading package punkt to /home/murphy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/murphy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/murphy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/murphy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/murphy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "INFO:elasticsearch:GET http://localhost:9200/ [status:200 request:0.005s]\n",
      "INFO:elasticsearch:POST http://localhost:9200/elastic_index/_search [status:200 request:0.051s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "•Relation:\n",
      "COVID-19\tcaused\t(WHO 2020\n",
      "•Source Sentence:\n",
      "COVID-19 should be recorded on the medical certificate of cause of death for ALL decedents where the disease caused, or is assumed to have caused, or contributed to death (WHO 2020, 3).On the one hand, when COVID-19 is not part of the causal chain that leads directly to death, it should not be indicated as the underlying cause of death.(From Paper: , COVID-19 as the underlying cause of death: disentangling facts and values)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "COVID-19\tcause\tpermanent damage to olfactory and gustatory function\n",
      "•Source Sentence:\n",
      "Does COVID-19 cause permanent damage to olfactory and gustatory function?(From Paper: , Journal Pre-proofs Does COVID-19 cause permanent damage to olfactory and gustatory func- tion? Does COVID-19 cause permanent damage to olfactory and gustatory function? Self-reported olfactory and taste disorders in SARSCoV-2 patients: a cross-sectional study Title: Does COVID-19 cause permanent damage to olfactory and gustatory function? Medical Hypotheses The Author declares there are no conflict of interest)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "COVID-19\tcause\tpermanent injury to olfactory and gustatory function\n",
      "•Source Sentence:\n",
      "CONCLUSIONS Although the mechanism of olfactory and gustatory function loss remains unclear [5], these preliminary clinical findings may indicate that relatively rapid recovery of olfactory and gustative function can mean a resolution of viral infection in most patients, and there was no distinction between hyposmia, anosmia and dysgeusia, contrary to what was found in other studies.[6] The analysis of our sample revealed that COVID-19 does not seem to cause permanent injury to olfactory and gustatory function because complete recovery occurs after two weeks.(From Paper: , Journal Pre-proofs Does COVID-19 cause permanent damage to olfactory and gustatory func- tion? Does COVID-19 cause permanent damage to olfactory and gustatory function? Self-reported olfactory and taste disorders in SARSCoV-2 patients: a cross-sectional study Title: Does COVID-19 cause permanent damage to olfactory and gustatory function? Medical Hypotheses The Author declares there are no conflict of interest)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "by COVID-19\tcaused\ta death\n",
      "•Source Sentence:\n",
      "In the case of COVID-19, the situation is further complicated by the fact that a death caused by COVID-19 could be correctly recorded even in cases where the infection is only suspected or probable.(From Paper: , COVID-19 as the underlying cause of death: disentangling facts and values)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "by COVID-19\tcaused\tthose deaths\n",
      "•Source Sentence:\n",
      "6 Diabetes and hypertensive diseases have been widely mentioned as increasing COVID-19 mortality risk and those deaths may actually have been caused by COVID-19.(From Paper: , New Insights on Excess Deaths and COVID-19)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "by COVID-19\tcaused\tthe definition of death\n",
      "•Source Sentence:\n",
      "Not only does the definition of death caused by COVID-19 admit \"a probable case\" of infection, but also the explicit instructions provided by WHO (2020) recommend that even in the case of mere suspicion of COVID-19, that is to say in the absence of swab or serological testing or other diagnostic imaging procedure that reliably confirms the infection, the disease must in any case be indicated as the underlying cause of death.(From Paper: , COVID-19 as the underlying cause of death: disentangling facts and values)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "COVID-19 infection\tcause\tmortality\n",
      "•Source Sentence:\n",
      "Our study showed that COVID-19 infection increased the risk of all-cause mortality regardless of comorbid status (HR:(From Paper: , Comparison all-cause mortality between individuals with COVID-19 and propensity- score-matched individuals without COVID-19 in South Korea)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "mortality from COVID-19 affects\tcause\tmortality\n",
      "•Source Sentence:\n",
      "The value of β 2 indicates the extent to which mortality from COVID-19 affects all-cause mortality in 2020 after adjusting for historical mortality patterns.(From Paper: , COVID-19 and excess mortality in the United States: A county-level analysis)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "Journal Pre-proofs Does COVID-19\tcause\tpermanent damage to olfactory and gustatory func- tion\n",
      "•Source Sentence:\n",
      "Journal Pre-proofs Does COVID-19 cause permanent damage to olfactory and gustatory func- tion?(From Paper: , Journal Pre-proofs Does COVID-19 cause permanent damage to olfactory and gustatory func- tion? Does COVID-19 cause permanent damage to olfactory and gustatory function? Self-reported olfactory and taste disorders in SARSCoV-2 patients: a cross-sectional study Title: Does COVID-19 cause permanent damage to olfactory and gustatory function? Medical Hypotheses The Author declares there are no conflict of interest)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "The statistics of COVID-19 cases and all\tcause\tmortality cases varied widely among the studied countries, which could lead to biased estimations of excess all-cause mortality in specific countries\n",
      "•Source Sentence:\n",
      "The statistics of COVID-19 cases and all-cause mortality cases varied widely among the studied countries, which could lead to biased estimations of excess all-cause mortality in specific countries.(From Paper: , Assessing the Country-Level Excess All-Cause Mortality and the Impacts of Air Pollution and Human Activity during the COVID-19 Epidemic)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "Incomplete COVID-19 cases in many countries\tcause\tthis issue\n",
      "•Source Sentence:\n",
      "Incomplete COVID-19 cases in many countries could also cause this issue.(From Paper: , Assessing the Country-Level Excess All-Cause Mortality and the Impacts of Air Pollution and Human Activity during the COVID-19 Epidemic)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "the inconsistency of COVID-19 mortality data and all\tcause\tmortality data among countries\n",
      "•Source Sentence:\n",
      "First, the inconsistency of COVID-19 mortality data and all-cause mortality data among countries should be considered.(From Paper: , Assessing the Country-Level Excess All-Cause Mortality and the Impacts of Air Pollution and Human Activity during the COVID-19 Epidemic)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      "================================================================================\n",
      "•Relation:\n",
      "direct deaths from unfamiliar complications of COVID-19 such as coagulopathy, myocarditis, inflammatory processes, and arrhythmias\tcaused\tconfusion\n",
      "•Source Sentence:\n",
      "Additionally, direct deaths from unfamiliar complications of COVID-19 such as coagulopathy, myocarditis, inflammatory processes, and arrhythmias may have caused confusion and led to attributions of death to other causes, especially early in the pandemic and among persons with comorbid conditions [7] [8] [9] .(From Paper: , COVID-19 and excess mortality in the United States: A county-level analysis)\n",
      "•UMLS Concepts:\n",
      " - covid-19\n",
      "\tName: COVID-19\tCUI: C5203670\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C5203670\n",
      " - myocarditis\n",
      "\tName: Myocarditis\tCUI: C0027059\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C0027059\n",
      "\tName: Myocarditis, CTCAE 5.0\tCUI: C4552880\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C4552880\n",
      "\tName: Viral myocarditis\tCUI: C0276138\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C0276138\n",
      "\tName: Viral Myocarditis Pathway\tCUI: C2984254\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C2984254\n",
      "\tName: Myocarditis, CTCAE 3.0\tCUI: C1962971\tLearn more at: https://www.ncbi.nlm.nih.gov/search/all/?term=C1962971\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use a response creator to format the result data packs into human readable formats.\n",
    "\"\"\"\n",
    "from composable_source.processors.response_creator import ResponseCreator\n",
    "nlp.add(ResponseCreator(), config=config.response)\n",
    "\n",
    "# Execute the pipeline once on one query and see the results \n",
    "nlp.initialize()\n",
    "data_pack = next(nlp.process_dataset())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
